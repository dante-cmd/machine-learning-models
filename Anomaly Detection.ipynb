{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anomaly Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detection is the task of detecting anomalies in data.\n",
    "\n",
    "How it works?\n",
    "\n",
    "- Train an algorithm on the training data\n",
    "  - This algorithm compute the probability of $P(X=x)$,this, based in the *density estimation* (or Kernel Density Estimation) on the training data.\n",
    "  - Compute the distance between the training data and the density estimation\n",
    "  - Compute the threshold\n",
    "  - Compute the anomaly score\n",
    "- Use the algorithm on the test data\n",
    "  - Compute the probability of $P(X=x_{\\text{test}})$, if the probability is lower than the threshold $\\epsilon$, the $x_{\\text{test}}$ is an anomaly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The user define the region of anomaly, that is, the threshold."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detection example\n",
    "- Fraud detection\n",
    "-"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detection algorithms\n",
    "\n",
    "1. Choose $n$ features $x_i$ that you think be indicative of the anomaly examples.\n",
    "\n",
    "2. Fit parameters $\\mu_1, \\mu_2, ..., \\mu_n$ and $\\sigma_1, \\sigma_2, ..., \\sigma_n$\n",
    "\n",
    "$$\\mu_j = \\frac{1}{n} \\sum_{j=1}^n x_j$$\n",
    "\n",
    "$$\\sigma_j = \\sqrt{\\frac{1}{n} \\sum_{j=1}^n (x_j - \\mu_i)^2}$$\n",
    "\n",
    "3. Given new example $x$, compute $p(x)$\n",
    "\n",
    "$$p(x)=\\prod_{j=1}^n \\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(x_j-\\mu)^2}{2\\sigma^2}\\right) $$\n",
    "\n",
    "4. If $p(x) < \\epsilon$, the new example is an anomaly\n",
    "\n",
    "> Note\n",
    "> If an feature is unusually large or small, this affects the overall probability $p(x)$ (decreasing it) and it is more likely to be an anomaly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The importance of real-number evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When developing a learning algorithm (choosing features, etc), making decisions is much easier if we have a way to evaluate our lerning algorithm.\n",
    "\n",
    "Assume we have some *labeled data*, of anomalous and non-anomalous examples. (e.g. $y=1$ if the example is anomalous and $y=0$ if the example is not anomalous).\n",
    "\n",
    "Training the algorithm on *training set* $x_1, x_2, ..., x_n$ and assume all examples are normal and labeled as $y=0$.\n",
    "\n",
    "Using *cross validation set* $((x_{cv}^{(1)}, y_{cv}^{(1)}), ..., (x_{cv}^{(k)}, y_{cv}^{(k)}))$ modify the parameters ($\\epsilon$) and the features that must include in the model. In the cross validation set we must include as anomalyes ($y=1$) examples as normal examples ($y=0$).\n",
    "\n",
    "Using test set $((x_{test}^{(1)}, y_{test}^{(1)}), ..., (x_{test}^{(k)}, y_{test}^{(k)}))$ we evaluate the algorithm on the test set. Here we must include as anomalyes ($y=1$) examples as normal examples ($y=0$).\n",
    "\n",
    "If we have a few examples, we only split the data into *training set* and *cross validation set*.\n",
    "\n",
    "Since the data is highly imbalanced, we can use *undersampling* to balance the data. In this case is highly recommended compute those *metrics*:\n",
    "\n",
    "- True positive rate, False positive rate, True negative rate, False negative rate\n",
    "- Precision, Recall\n",
    "- F1 score\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Anomaly detection vs Supervised Learning\n",
    "\n",
    "- Anomaly detection \n",
    "  - Works on very small positive examples ($y = 1$). (0-20 is common) and very large negative examples ($y = 0$).\n",
    "  - Exists many types of anomalies. Hard for any algorithm to learn from positive examples what the anomalies look like.\n",
    "  - Future anomalies may look nothing like any of the anomaous examples we've seen so far.\n",
    "  - e.g. *fraud*\n",
    "\n",
    "- Supervised learning\n",
    "  - Large number of positive and negative examples.\n",
    "  - Enough examples for algorithm to get a sense of what postive examples are like, future positive examples likely to be similar to ones in training set.\n",
    "  - e.g. *spam*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the non-gaussian data to gaussian data\n",
    "- $\\ln(x+c)$. The c avoiding log(0)\n",
    "- $x^{1/n}$\n",
    "\n",
    "While more features can add to model, we can use it to detect anomalies.\n",
    "- Only 2 or 3 features is not enough to detect anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import h2o\n",
    "from h2o.estimators.isolation_forest import H2OIsolationForestEstimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
